{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dip.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/needle1989/Image-Classification-for-CONV-19/blob/testtrain/dip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8nLm_ftg71b"
      },
      "source": [
        "! unzip /content/drive/MyDrive/trainData.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nSCAGka09oi"
      },
      "source": [
        "! du -h --max-depth=1 trainData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N7joW31pbIS"
      },
      "source": [
        "! git clone https://github.com/needle1989/Image-Classification-for-CONV-19.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xPwPliQ-kbH"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import csv\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "# load csv file\n",
        "f = open('trainData/slice-level/Slice_level_label.csv')\n",
        "tag = list(csv.reader(f))\n",
        "# root path for train set\n",
        "root_cap = \"trainData/slice-level/Cap/\"\n",
        "root_p = \"trainData/slice-level/Covid-19/\"\n",
        "\n",
        "\n",
        "# return root path for every image in this folder\n",
        "def file_name(file_dir):\n",
        "    ct_img = []\n",
        "    for root, dirs, files in os.walk(file_dir):\n",
        "        for file in files:\n",
        "            ct_img.append(root + \"/\" + file)\n",
        "    return ct_img\n",
        "\n",
        "\n",
        "def default_loader(path):\n",
        "    return Image.open(path).convert('RGB')\n",
        "\n",
        "\n",
        "class LoadData(Dataset):\n",
        "    def __init__(self, transform=None, target_transform=None, loader=default_loader):\n",
        "        imgs = []\n",
        "        p_sample = 0\n",
        "        while p_sample < 55:\n",
        "            p_sample = p_sample + 1\n",
        "            p = file_name(root_p + tag[p_sample][0])\n",
        "            print(len(p))\n",
        "            for num in range(len(p)):\n",
        "                print(p[num])\n",
        "                print(tag[p_sample][num + 1])\n",
        "                imgs.append((p[num], int(tag[p_sample][num + 1])))\n",
        "        cap_sample = 55\n",
        "        while cap_sample < 80:\n",
        "            cap_sample = cap_sample + 1\n",
        "            cap = file_name(root_cap + tag[cap_sample][0])\n",
        "            print(len(cap))\n",
        "            for num in range(len(cap)):\n",
        "                print(cap[num])\n",
        "                print(tag[cap_sample][num + 1])\n",
        "                cap_tag = int(tag[cap_sample][num + 1])\n",
        "                if cap_tag == 1:\n",
        "                    cap_tag = cap_tag + 1\n",
        "                imgs.append((cap[num], cap_tag))\n",
        "        self.imgs = imgs\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.loader = loader\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        fn, label = self.imgs[index]\n",
        "        img = self.loader(fn)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "'''\n",
        "class Unit(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super(Unit,self).__init__()\n",
        "        \n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,kernel_size=3,out_channels=out_channels,stride=1,padding=1)\n",
        "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,input):\n",
        "        output = self.conv(input)\n",
        "        output = self.bn(output)\n",
        "        output = self.relu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(SimpleNet,self).__init__()\n",
        "\n",
        "        #Create 14 layers of the unit with max pooling in between\n",
        "        self.unit1 = Unit(in_channels=3,out_channels=32)\n",
        "        self.unit2 = Unit(in_channels=32, out_channels=32)\n",
        "        self.unit3 = Unit(in_channels=32, out_channels=32)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit4 = Unit(in_channels=32, out_channels=64)\n",
        "        self.unit5 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit6 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit7 = Unit(in_channels=64, out_channels=64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit8 = Unit(in_channels=64, out_channels=128)\n",
        "        self.unit9 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit10 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit11 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit12 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit13 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit14 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
        "        \n",
        "        #Add all the units into the Sequential layer in exact order\n",
        "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4, self.unit5, self.unit6\n",
        "                                 ,self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11, self.pool3,\n",
        "                                 self.unit12, self.unit13, self.unit14, self.avgpool)\n",
        "        \n",
        "        self.fc = nn.Linear(in_features=128*16*16,out_features=num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.net(input)\n",
        "        output = output.view(output.size(0),-1)\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "'''\n",
        "#Define transformations for the training set, flip the images randomly, crop out and apply mean and std normalization\n",
        "train_transformations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(512,padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_set = LoadData(transform=train_transformations);\n",
        "\n",
        "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "\n",
        "#Check if gpu support is available\n",
        "cuda_avail = torch.cuda.is_available()\n",
        "\n",
        "#Create model, optimizer and loss function\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "fc_inputs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(fc_inputs, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(256, 3),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ")\n",
        "\n",
        "    \n",
        "if cuda_avail:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001,weight_decay=0.0001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Create a learning rate adjustment function that divides the learning rate by 10 every 30 epochs\n",
        "def adjust_learning_rate(epoch):\n",
        "\n",
        "    lr = 0.001\n",
        "\n",
        "    if epoch > 180:\n",
        "        lr = lr / 1000000\n",
        "    elif epoch > 150:\n",
        "        lr = lr / 100000\n",
        "    elif epoch > 120:\n",
        "        lr = lr / 10000\n",
        "    elif epoch > 90:\n",
        "        lr = lr / 1000\n",
        "    elif epoch > 60:\n",
        "        lr = lr / 100\n",
        "    elif epoch > 30:\n",
        "        lr = lr / 10\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "\n",
        "def save_models(epoch):\n",
        "    torch.save(model.state_dict(), \"covid_classify_model_{}.model\".format(epoch))\n",
        "    print(\"Checkpoint saved\")\n",
        "\n",
        "\n",
        "def train(num_epochs):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_acc = 0.0\n",
        "        train_loss = 0.0\n",
        "        total = 0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            #Move images and labels to gpu if available\n",
        "            if cuda_avail:\n",
        "                images = Variable(images.cuda())\n",
        "                labels = Variable(labels.cuda())\n",
        "\n",
        "            #Clear all accumulated gradients\n",
        "            optimizer.zero_grad()\n",
        "            #Predict classes using images from the test set\n",
        "            outputs = model(images)\n",
        "            total += labels.size(0)\n",
        "            #Compute the loss based on the predictions and actual labels\n",
        "            loss = loss_fn(outputs,labels)\n",
        "            #Backpropagate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            #Adjust parameters according to the computed gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.cpu().item() * images.size(0)\n",
        "            _, prediction = torch.max(outputs.data, 1)\n",
        "            \n",
        "            train_acc += torch.sum(prediction == labels.data)\n",
        "\n",
        "        #Call the learning rate adjustment function\n",
        "        adjust_learning_rate(epoch)\n",
        "\n",
        "        #Compute the average acc and loss over all training images\n",
        "        train_acc = train_acc / total\n",
        "        train_loss = train_loss / total\n",
        "\n",
        "\n",
        "        # Save the model if the test acc is greater than our current best\n",
        "        if train_acc > best_acc:\n",
        "            save_models(epoch)\n",
        "            best_acc = train_acc\n",
        "\n",
        "\n",
        "        # Print the metrics\n",
        "        print(\"Epoch {}, Train Accuracy: {} , TrainLoss: {} \".format(epoch, train_acc, train_loss))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train(200)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ev7ZLIcpXw"
      },
      "source": [
        "! ps -aux"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXrw9C3YdW18"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOLDqLFHAF0k"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJA06RFAeXOW"
      },
      "source": [
        "!apt install psmisc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OJL9UxmeY52"
      },
      "source": [
        "!sudo fuser /dev/nvidia*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRK-UgPjekW1"
      },
      "source": [
        "!kill -9 56"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}